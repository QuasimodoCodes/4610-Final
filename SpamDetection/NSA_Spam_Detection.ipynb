{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30d7705a",
   "metadata": {},
   "source": [
    "# AIS Negative Selection Algorithm (NSA) for Spam Detection\n",
    "*Generated:* 2025-10-18T13:11:53.911542Z\n",
    "\n",
    "This notebook sets up a runnable pipeline to detect spam using **Artificial Immune Systems** (AIS), specifically the **Negative Selection Algorithm (NSA)**:\n",
    "- Learn *self* from ham only\n",
    "- Generate detectors that do **not** match self (under r-contiguous or Hamming rules)\n",
    "- Flag a message as spam if it matches **any** detector\n",
    "- Evaluate with Precision/Recall/F1 (spam), ROC-AUC, PR-AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3281f318",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1622df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy pandas scikit-learn matplotlib tqdm\n",
    "\n",
    "import os, re, hashlib, random\n",
    "from textwrap import dedent\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score, roc_curve, precision_recall_curve, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reproducibility\n",
    "RNG_SEED = 42\n",
    "random.seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n",
    "\n",
    "# Data config\n",
    "DATA_PATH = \"\"  # e.g., \"SMSSpamCollection\" or \"your_data.csv\"\n",
    "DATA_FORMAT = \"auto\"  # 'auto' | 'smsspam' | 'csv'\n",
    "\n",
    "# Encoding & NSA config\n",
    "NGRAM_N = 3                  # character n-gram length\n",
    "BIT_LENGTH = 256             # length of binary encoding\n",
    "RADIUS_R = 8                 # r for r-contiguous match\n",
    "HAMMING_T = 12               # Hamming distance threshold\n",
    "MATCH_RULE = \"r_contiguous\"  # 'r_contiguous' | 'hamming'\n",
    "\n",
    "# Detector generation\n",
    "NUM_DETECTORS = 2000\n",
    "MAX_ATTEMPTS = 100000\n",
    "MAX_PER_MESSAGE_HITS = 1     # >= hits -> spam\n",
    "\n",
    "# Splits\n",
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE = 0.1\n",
    "\n",
    "# Preprocessing\n",
    "LOWERCASE = True\n",
    "STRIP_PUNCT = True\n",
    "KEEP_DIGITS = True\n",
    "NORMALIZE_WHITESPACE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f6283d",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472a6ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_auto(path: str) -> pd.DataFrame:\n",
    "    # Return DataFrame with columns ['label','text'] and label in {'ham','spam'}\n",
    "    if not path or not os.path.exists(path):\n",
    "        raise FileNotFoundError(\"Set DATA_PATH to your dataset file.\")\n",
    "    if path.endswith(\"SMSSpamCollection\") or DATA_FORMAT in (\"smsspam\",\"auto\"):\n",
    "        try:\n",
    "            df = pd.read_csv(path, sep=\"\\t\", header=None, names=[\"label\",\"text\"])\n",
    "            if set(df.columns)=={\"label\",\"text\"} and set(df[\"label\"].unique())=={\"ham\",\"spam\"}:\n",
    "                return df\n",
    "        except Exception:\n",
    "            pass\n",
    "    if path.endswith(\".csv\") or DATA_FORMAT in (\"csv\",\"auto\"):\n",
    "        df = pd.read_csv(path)\n",
    "        assert {\"label\",\"text\"}.issubset(df.columns), \"CSV must have 'label' and 'text' columns.\"\n",
    "        df[\"label\"] = df[\"label\"].astype(str).str.lower().map({\"ham\":\"ham\",\"spam\":\"spam\"})\n",
    "        assert df[\"label\"].isin({\"ham\",\"spam\"}).all(), \"Labels must be 'ham' or 'spam'.\"\n",
    "        return df\n",
    "    raise ValueError(\"Unrecognized data format.\")\n",
    "\n",
    "def demo_data() -> pd.DataFrame:\n",
    "    ham = [\n",
    "        \"Are we still on for lunch today at 12?\",\n",
    "        \"Don't forget the meeting tomorrow morning.\",\n",
    "        \"Please review the attached report and let me know your thoughts.\",\n",
    "        \"Happy birthday! Hope you have a great day.\",\n",
    "        \"I'll be there in 10 minutes.\"\n",
    "    ]\n",
    "    spam = [\n",
    "        \"WINNER!! Claim your free prize now, click here http://spam.biz\",\n",
    "        \"Congratulations! You've been selected. Reply with BANK details to receive $1000.\",\n",
    "        \"Urgent! Your account is compromised. Verify now at fake-site.com\",\n",
    "        \"You won a lottery!!! Send your SSN ASAP to claim.\",\n",
    "        \"Limited-time offer: Buy now and get 90% off!\"\n",
    "    ]\n",
    "    return pd.DataFrame([{\"label\":\"ham\",\"text\":t} for t in ham] + [{\"label\":\"spam\",\"text\":t} for t in spam])\n",
    "\n",
    "try:\n",
    "    if DATA_PATH:\n",
    "        df = load_data_auto(DATA_PATH)\n",
    "    else:\n",
    "        print(\"No DATA_PATH set. Using a tiny demo dataset.\")\n",
    "        df = demo_data()\n",
    "except Exception as e:\n",
    "    print(\"Data load failed, using demo dataset:\", e)\n",
    "    df = demo_data()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de455d8a",
   "metadata": {},
   "source": [
    "## 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30d025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCT_RE = re.compile(r\"[\\w\\s]\" if KEEP_DIGITS else r\"[A-Za-z\\s]\")\n",
    "\n",
    "def preprocess(text: str) -> str:\n",
    "    s = str(text) if text is not None else \"\"\n",
    "    if LOWERCASE:\n",
    "        s = s.lower()\n",
    "    if STRIP_PUNCT:\n",
    "        # keep letters/digits/underscore/space by filtering char-wise\n",
    "        s = \"\".join(ch if (ch.isalnum() or ch.isspace() or ch=='_') else \" \" for ch in s)\n",
    "    if NORMALIZE_WHITESPACE:\n",
    "        s = \" \".join(s.split())\n",
    "    return s\n",
    "\n",
    "df[\"text_clean\"] = df[\"text\"].map(preprocess)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7312a263",
   "metadata": {},
   "source": [
    "## 4. Encoding to Fixed-Length Binary (hashed character n-grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14428212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_ngrams(s: str, n: int) -> List[str]:\n",
    "    if len(s) < n:\n",
    "        return [s] if s else []\n",
    "    return [s[i:i+n] for i in range(len(s)-n+1)]\n",
    "\n",
    "def hash_to_bits(token: str, bit_length: int) -> np.ndarray:\n",
    "    h = hashlib.sha256(token.encode(\"utf-8\")).digest()\n",
    "    bits = np.unpackbits(np.frombuffer(h, dtype=np.uint8))\n",
    "    if bit_length == 256:\n",
    "        return bits.astype(np.uint8)\n",
    "    folded = np.zeros(bit_length, dtype=np.uint16)\n",
    "    for i, b in enumerate(bits):\n",
    "        folded[i % bit_length] += int(b)\n",
    "    return (folded % 2).astype(np.uint8)\n",
    "\n",
    "def encode_message(s: str, n: int, bit_length: int) -> np.ndarray:\n",
    "    grams = char_ngrams(s, n)\n",
    "    if not grams:\n",
    "        return np.zeros(bit_length, dtype=np.uint8)\n",
    "    acc = np.zeros(bit_length, dtype=np.uint8)\n",
    "    for g in grams:\n",
    "        acc ^= hash_to_bits(g, bit_length)\n",
    "    return acc\n",
    "\n",
    "X_bits = np.vstack([encode_message(s, NGRAM_N, BIT_LENGTH) for s in tqdm(df[\"text_clean\"], desc=\"Encoding\")])\n",
    "y = (df[\"label\"].values == \"spam\").astype(np.uint8)\n",
    "X_bits.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa324b0b",
   "metadata": {},
   "source": [
    "## 5. Train / Validation / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9648d092",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, df_train, df_test = train_test_split(\n",
    "    X_bits, y, df, test_size=TEST_SIZE, random_state=RNG_SEED, stratify=y\n",
    ")\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=VAL_SIZE, random_state=RNG_SEED, stratify=y_train\n",
    ")\n",
    "X_self = X_tr[y_tr == 0]\n",
    "len(X_self), X_self.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90b2a55",
   "metadata": {},
   "source": [
    "## 6. Matching Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c12b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_contiguous_match(a: np.ndarray, b: np.ndarray, r: int) -> bool:\n",
    "    eq = (a == b).astype(np.uint8)\n",
    "    run = 0\n",
    "    for bit in eq:\n",
    "        if bit == 1:\n",
    "            run += 1\n",
    "            if run >= r:\n",
    "                return True\n",
    "        else:\n",
    "            run = 0\n",
    "    return False\n",
    "\n",
    "def hamming_match(a: np.ndarray, b: np.ndarray, t: int) -> bool:\n",
    "    return int(np.sum(a != b)) <= t\n",
    "\n",
    "def matches_any(x: np.ndarray, detectors: np.ndarray, rule: str) -> bool:\n",
    "    if detectors.size == 0:\n",
    "        return False\n",
    "    if rule == \"r_contiguous\":\n",
    "        for d in detectors:\n",
    "            if r_contiguous_match(x, d, RADIUS_R):\n",
    "                return True\n",
    "        return False\n",
    "    elif rule == \"hamming\":\n",
    "        for d in detectors:\n",
    "            if hamming_match(x, d, HAMMING_T):\n",
    "                return True\n",
    "        return False\n",
    "    else:\n",
    "        raise ValueError(\"Unknown MATCH_RULE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e836f1ca",
   "metadata": {},
   "source": [
    "## 7. Detector Generation (Negative Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6d433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_bitstring(bit_length: int) -> np.ndarray:\n",
    "    return (np.random.rand(bit_length) > 0.5).astype(np.uint8)\n",
    "\n",
    "def detector_matches_self(candidate: np.ndarray, X_self: np.ndarray, rule: str) -> bool:\n",
    "    if rule == \"r_contiguous\":\n",
    "        for s in X_self:\n",
    "            if r_contiguous_match(candidate, s, RADIUS_R):\n",
    "                return True\n",
    "        return False\n",
    "    elif rule == \"hamming\":\n",
    "        for s in X_self:\n",
    "            if hamming_match(candidate, s, HAMMING_T):\n",
    "                return True\n",
    "        return False\n",
    "    else:\n",
    "        raise ValueError(\"Unknown MATCH_RULE\")\n",
    "\n",
    "def generate_detectors(num_detectors: int, max_attempts: int, X_self: np.ndarray, rule: str) -> np.ndarray:\n",
    "    detectors = []\n",
    "    attempts = 0\n",
    "    pbar = tqdm(total=num_detectors, desc=\"Generating detectors\")\n",
    "    while len(detectors) < num_detectors and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        cand = random_bitstring(BIT_LENGTH)\n",
    "        if not detector_matches_self(cand, X_self, rule):\n",
    "            detectors.append(cand)\n",
    "            pbar.update(1)\n",
    "    pbar.close()\n",
    "    print(f\"Generated {len(detectors)} detectors with {attempts} attempts.\")\n",
    "    return np.array(detectors, dtype=np.uint8)\n",
    "\n",
    "detectors = generate_detectors(NUM_DETECTORS, MAX_ATTEMPTS, X_self, MATCH_RULE)\n",
    "detectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17546fc9",
   "metadata": {},
   "source": [
    "## 8. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfddc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_spam(X: np.ndarray, detectors: np.ndarray, rule: str, min_hits: int = 1) -> np.ndarray:\n",
    "    preds = np.zeros(X.shape[0], dtype=np.uint8)\n",
    "    for i, x in enumerate(tqdm(X, desc=\"Classifying\")):\n",
    "        hits = 0\n",
    "        if detectors.size > 0:\n",
    "            if rule == \"r_contiguous\":\n",
    "                for d in detectors:\n",
    "                    if r_contiguous_match(x, d, RADIUS_R):\n",
    "                        hits += 1\n",
    "                        if hits >= min_hits:\n",
    "                            preds[i] = 1\n",
    "                            break\n",
    "            elif rule == \"hamming\":\n",
    "                for d in detectors:\n",
    "                    if hamming_match(x, d, HAMMING_T):\n",
    "                        hits += 1\n",
    "                        if hits >= min_hits:\n",
    "                            preds[i] = 1\n",
    "                            break\n",
    "            else:\n",
    "                raise ValueError(\"Unknown MATCH_RULE\")\n",
    "    return preds\n",
    "\n",
    "y_val_pred = predict_spam(X_val, detectors, MATCH_RULE, min_hits=MAX_PER_MESSAGE_HITS)\n",
    "print(classification_report(y_val, y_val_pred, target_names=[\"ham\",\"spam\"], digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff52184",
   "metadata": {},
   "source": [
    "## 9. Quick Parameter Sweep on Validation (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50122ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(y_true, y_pred):\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "    return {\"precision\": p, \"recall\": r, \"f1\": f1}\n",
    "\n",
    "min_hits_grid = [1, 2, 3]\n",
    "results = []\n",
    "for mh in min_hits_grid:\n",
    "    preds = predict_spam(X_val, detectors, MATCH_RULE, min_hits=mh)\n",
    "    metrics = evaluate_preds(y_val, preds)\n",
    "    metrics[\"min_hits\"] = mh\n",
    "    results.append(metrics)\n",
    "\n",
    "pd.DataFrame(results).sort_values(\"f1\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4066403b",
   "metadata": {},
   "source": [
    "## 10. Final Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556fb0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_min_hits(X_val, y_val, detectors) -> int:\n",
    "    grid = [1, 2, 3]\n",
    "    best_f1, best_mh = -1, 1\n",
    "    for mh in grid:\n",
    "        preds = predict_spam(X_val, detectors, MATCH_RULE, min_hits=mh)\n",
    "        p, r, f1, _ = precision_recall_fscore_support(y_val, preds, average=\"binary\", zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_mh = f1, mh\n",
    "    return best_mh\n",
    "\n",
    "best_mh = best_min_hits(X_val, y_val, detectors)\n",
    "print(\"Best min_hits from validation:\", best_mh)\n",
    "\n",
    "y_test_pred = predict_spam(X_test, detectors, MATCH_RULE, min_hits=best_mh)\n",
    "print(classification_report(y_test, y_test_pred, target_names=[\"ham\",\"spam\"], digits=4))\n",
    "\n",
    "def match_counts(X: np.ndarray, detectors: np.ndarray, rule: str) -> np.ndarray:\n",
    "    scores = np.zeros(X.shape[0], dtype=np.float32)\n",
    "    for i, x in enumerate(tqdm(X, desc=\"Scoring\")):\n",
    "        hits = 0\n",
    "        if detectors.size > 0:\n",
    "            if rule == \"r_contiguous\":\n",
    "                for d in detectors:\n",
    "                    if r_contiguous_match(x, d, RADIUS_R):\n",
    "                        hits += 1\n",
    "            elif rule == \"hamming\":\n",
    "                for d in detectors:\n",
    "                    if hamming_match(x, d, HAMMING_T):\n",
    "                        hits += 1\n",
    "            else:\n",
    "                raise ValueError(\"Unknown MATCH_RULE\")\n",
    "        scores[i] = hits\n",
    "    return scores\n",
    "\n",
    "scores = match_counts(X_test, detectors, MATCH_RULE)\n",
    "if scores.max() > 0:\n",
    "    scores_norm = (scores - scores.min()) / (scores.max() - scores.min())\n",
    "else:\n",
    "    scores_norm = scores\n",
    "\n",
    "try:\n",
    "    roc = roc_auc_score(y_test, scores_norm)\n",
    "except Exception:\n",
    "    roc = float(\"nan\")\n",
    "try:\n",
    "    pr_auc = average_precision_score(y_test, scores_norm)\n",
    "except Exception:\n",
    "    pr_auc = float(\"nan\")\n",
    "print(f\"ROC-AUC: {roc:.4f} | PR-AUC: {pr_auc:.4f}\")\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, scores_norm)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=\"ROC\")\n",
    "plt.plot([0,1], [0,1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve (NSA Spam Detection)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "prec, rec, _ = precision_recall_curve(y_test, scores_norm)\n",
    "plt.figure()\n",
    "plt.plot(rec, prec, label=\"PR\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve (NSA Spam Detection)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a85db5",
   "metadata": {},
   "source": [
    "## 11. Utilities & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8009f4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regenerate_detectors(new_num_detectors=None, new_rule=None):\n",
    "    global detectors\n",
    "    n = int(new_num_detectors) if new_num_detectors is not None else NUM_DETECTORS\n",
    "    rule = new_rule or MATCH_RULE\n",
    "    detectors = generate_detectors(n, MAX_ATTEMPTS, X_self, rule)\n",
    "    return detectors\n",
    "\n",
    "def quick_eval_on_val(min_hits=1):\n",
    "    preds = predict_spam(X_val, detectors, MATCH_RULE, min_hits=min_hits)\n",
    "    print(classification_report(y_val, preds, target_names=[\"ham\",\"spam\"], digits=4))\n",
    "\n",
    "print(dedent(\"\"\"\n",
    "Notes:\n",
    "- Increase NUM_DETECTORS for better coverage (more recall), but runtime increases.\n",
    "- Tune RADIUS_R (r-contiguous) or HAMMING_T (Hamming) to balance precision/recall.\n",
    "- Replace demo data by setting DATA_PATH to your real dataset.\n",
    "- Consider vectorization or sub-sampling self to speed up detector generation.\n",
    "\"\"\"))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
