{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Warehouse Robot Navigation Using Q-Learning\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook implements a reinforcement learning solution to the warehouse robot navigation problem using Q-learning. The robot must navigate from a loading bay to a target shelf on a slippery floor while avoiding hazards (holes).\n",
        "\n",
        "## Problem Statement\n",
        "\n",
        "We use the FrozenLake-v1 environment from Gymnasium, which models:\n",
        "\n",
        "- **Environment**: A slippery warehouse floor represented as a grid\n",
        "- **Agent**: A warehouse robot that can move in 4 directions (Left, Down, Right, Up)\n",
        "- **Goal**: Navigate from start (S) to goal (G) while avoiding holes (H)\n",
        "- **Challenge**: Stochastic transitions due to slippery surface (actions may slip)\n",
        "\n",
        "## Tasks\n",
        "\n",
        "1. Understanding the Environment\n",
        "2. Setting Up the Q-Learning Agent\n",
        "3. Training the Agent\n",
        "4. Evaluation & Comparison with Baselines\n",
        "5. Hyperparameter Optimization\n",
        "6. Testing on Larger Maps (8Ã—8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All libraries imported successfully!\n",
            "Gymnasium version: 1.2.1\n",
            "NumPy version: 1.26.4\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "import time\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"All libraries imported successfully!\")\n",
        "print(f\"Gymnasium version: {gym.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Understanding the Environment\n",
        "\n",
        "In this section, we explore the FrozenLake-v1 environment to understand:\n",
        "\n",
        "- State space (observation space)\n",
        "- Action space\n",
        "- Grid layout (Start, Goal, Holes, Frozen tiles)\n",
        "- Reward structure\n",
        "- Effect of slippery=True (stochastic transitions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Create FrozenLake Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "FROZENLAKE ENVIRONMENT CREATED\n",
            "============================================================\n",
            "Environment: FrozenLake-v1\n",
            "Map: 4x4\n",
            "Slippery: True (stochastic transitions)\n"
          ]
        }
      ],
      "source": [
        "# Create FrozenLake environment with slippery surface\n",
        "# Starting with 4x4 map (default)\n",
        "env = gym.make('FrozenLake-v1', map_name=\"4x4\", is_slippery=True, render_mode='ansi')\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"FROZENLAKE ENVIRONMENT CREATED\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Environment: {env.spec.id}\")\n",
        "print(f\"Map: 4x4\")\n",
        "print(f\"Slippery: True (stochastic transitions)\")\n",
        "# print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Inspect State and Action Spaces\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " STATE SPACE (Observation Space):\n",
            "   Type: Discrete(16)\n",
            "   Number of states: 16\n",
            "   Description: Each tile on the grid is a discrete state (0 to 15)\n",
            "\n",
            " ACTION SPACE:\n",
            "   Type: Discrete(4)\n",
            "   Number of actions: 4\n",
            "   Actions mapping:\n",
            "      0 = LEFT\n",
            "      1 = DOWN\n",
            "      2 = RIGHT\n",
            "      3 = UP\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Print observation and action spaces\n",
        "print(\"\\n STATE SPACE (Observation Space):\")\n",
        "print(f\"   Type: {env.observation_space}\")\n",
        "print(f\"   Number of states: {env.observation_space.n}\")\n",
        "print(f\"   Description: Each tile on the grid is a discrete state (0 to {env.observation_space.n - 1})\")\n",
        "\n",
        "print(\"\\n ACTION SPACE:\")\n",
        "print(f\"   Type: {env.action_space}\")\n",
        "print(f\"   Number of actions: {env.action_space.n}\")\n",
        "print(f\"   Actions mapping:\")\n",
        "print(f\"      0 = LEFT\")\n",
        "print(f\"      1 = DOWN\")\n",
        "print(f\"      2 = RIGHT\")\n",
        "print(f\"      3 = UP\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Visualize the Grid\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " GRID LAYOUT (4x4 Map):\n",
            "============================================================\n",
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "\n",
            "============================================================\n",
            "\n",
            " Legend:\n",
            "   S = Start (loading bay) - Initial position\n",
            "   F = Frozen (safe tile) - Can walk on\n",
            "   H = Hole (hazard/spill) - Episode ends, reward = 0\n",
            "   G = Goal (target shelf) - Episode ends, reward = +1\n",
            "\n",
            "   The robot starts at 'S' and must reach 'G' while avoiding 'H'\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Reset environment and visualize the grid\n",
        "state, info = env.reset()\n",
        "grid_render = env.render()\n",
        "\n",
        "print(\"\\n GRID LAYOUT (4x4 Map):\")\n",
        "print(\"=\" * 60)\n",
        "print(grid_render)\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n Legend:\")\n",
        "print(\"   S = Start (loading bay) - Initial position\")\n",
        "print(\"   F = Frozen (safe tile) - Can walk on\")\n",
        "print(\"   H = Hole (hazard/spill) - Episode ends, reward = 0\")\n",
        "print(\"   G = Goal (target shelf) - Episode ends, reward = +1\")\n",
        "print(\"\\n   The robot starts at 'S' and must reach 'G' while avoiding 'H'\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Reward Structure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " REWARD STRUCTURE:\n",
            "============================================================\n",
            "   Reaching Goal (G):      +1.0  (episode terminates)\n",
            "   Falling into Hole (H):   0.0  (episode terminates)\n",
            "   Safe tile (F or S):      0.0  (continue episode)\n",
            "============================================================\n",
            "\n",
            "  SPARSE REWARD CHALLENGE:\n",
            "   - Agent only gets reward when reaching the goal\n",
            "   - No intermediate feedback during navigation\n",
            "   - Must explore extensively to discover successful paths\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n REWARD STRUCTURE:\")\n",
        "print(\"=\" * 60)\n",
        "print(\"   Reaching Goal (G):      +1.0  (episode terminates)\")\n",
        "print(\"   Falling into Hole (H):   0.0  (episode terminates)\")\n",
        "print(\"   Safe tile (F or S):      0.0  (continue episode)\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n  SPARSE REWARD CHALLENGE:\")\n",
        "print(\"   - Agent only gets reward when reaching the goal\")\n",
        "print(\"   - No intermediate feedback during navigation\")\n",
        "print(\"   - Must explore extensively to discover successful paths\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5 Demonstration: Effect of Slippery Floor (Stochastic Transitions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " SLIPPERY FLOOR EFFECT (is_slippery=True):\n",
            "============================================================\n",
            "When the robot attempts an action, the floor is slippery!\n",
            "The actual movement has stochastic (random) transitions:\n",
            "\n",
            "   Intended direction:  33.3% chance\n",
            "   Perpendicular left:  33.3% chance\n",
            "   Perpendicular right: 33.3% chance\n",
            "\n",
            "Example: If robot tries to move RIGHT:\n",
            "   â†’ 33% moves RIGHT (intended)\n",
            "   â†’ 33% moves UP (perpendicular)\n",
            "   â†’ 33% moves DOWN (perpendicular)\n",
            "\n",
            " REAL-WORLD ANALOGY:\n",
            "   - Slippery warehouse floor with water/oil spills\n",
            "   - Wheels may slip in unexpected directions\n",
            "   - Must learn robust policy that handles uncertainty\n",
            "============================================================\n",
            "\n",
            " DEMONSTRATION: Trying to move RIGHT 10 times from start\n",
            "============================================================\n",
            "Starting state: 0 (always starts at same position)\n",
            "Action taken: RIGHT (action=2)\n",
            "\n",
            "Resulting states after action: [4, 0, 1, 4, 4, 1, 1, 0, 1, 4]\n",
            "Unique states reached: {0, 1, 4}\n",
            "\n",
            " Notice: Even with the same action, we reach different states!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n SLIPPERY FLOOR EFFECT (is_slippery=True):\")\n",
        "print(\"=\" * 60)\n",
        "print(\"When the robot attempts an action, the floor is slippery!\")\n",
        "print(\"The actual movement has stochastic (random) transitions:\\n\")\n",
        "print(\"   Intended direction:  33.3% chance\")\n",
        "print(\"   Perpendicular left:  33.3% chance\")\n",
        "print(\"   Perpendicular right: 33.3% chance\")\n",
        "print(\"\\nExample: If robot tries to move RIGHT:\")\n",
        "print(\"   â†’ 33% moves RIGHT (intended)\")\n",
        "print(\"   â†’ 33% moves UP (perpendicular)\")\n",
        "print(\"   â†’ 33% moves DOWN (perpendicular)\")\n",
        "print(\"\\n REAL-WORLD ANALOGY:\")\n",
        "print(\"   - Slippery warehouse floor with water/oil spills\")\n",
        "print(\"   - Wheels may slip in unexpected directions\")\n",
        "print(\"   - Must learn robust policy that handles uncertainty\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Demonstrate with a simple test\n",
        "print(\"\\n DEMONSTRATION: Trying to move RIGHT 10 times from start\")\n",
        "print(\"=\" * 60)\n",
        "action_right = 2  # RIGHT\n",
        "outcomes = []\n",
        "\n",
        "for i in range(10):\n",
        "    state, info = env.reset()\n",
        "    next_state, reward, terminated, truncated, info = env.step(action_right)\n",
        "    outcomes.append(next_state)\n",
        "    \n",
        "print(f\"Starting state: {state} (always starts at same position)\")\n",
        "print(f\"Action taken: RIGHT (action={action_right})\")\n",
        "print(f\"\\nResulting states after action: {outcomes}\")\n",
        "print(f\"Unique states reached: {set(outcomes)}\")\n",
        "print(\"\\n Notice: Even with the same action, we reach different states!\")\n",
        "print(\"=\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
